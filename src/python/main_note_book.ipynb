{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "from network.metric.accuracy import acc_srcnn_tiny_radar\n",
    "from network.models.classifiers.tiny_radar import TinyRadarNN\n",
    "from network.models.sr_classifier.SRCnnTinyRadar import CombinedSRCNNClassifier\n",
    "from network.models.super_resolution.drln import Drln\n",
    "from network.models.super_resolution.srcnn import SRCnn\n",
    "from network.runner import Runner\n",
    "from utils.utils_paths import get_time_in_string\n",
    "from utils.utils_images import Normalization\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft, fftshift, ifftshift, ifft\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from data_loader.tiny_loader import load_tiny_data_sr\n",
    "from data_loader.tiny_loader import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class ReconstractDataset(Dataset):\n",
    "    def __init__(self, imgs):\n",
    "        self.imgs = imgs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.imgs.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        high_res = self.imgs[idx]\n",
    "        low_res = fftshift(fft(high_res, axis=0), axes=0)\n",
    "\n",
    "\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 5, 32, 492, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_loader.tiny_radar_loader import tiny_radar_for_classifier, tiny_tt\n",
    "from training_scripts.training_sr import train_drln\n",
    "\n",
    "\n",
    "numberOfInstanceWindows = 3\n",
    "lengthOfSubWindow = 32\n",
    "\n",
    "gestures = [\n",
    "        \"PinchIndex\",\n",
    "        \"PinchPinky\",\n",
    "        # \"FingerSlider\",\n",
    "        # \"FingerRub\",\n",
    "        # \"SlowSwipeRL\",\n",
    "        # \"FastSwipeRL\",\n",
    "        # \"Push\",\n",
    "        # \"Pull\",\n",
    "        # \"PalmTilt\",\n",
    "        # \"Circle\",\n",
    "        # \"PalmHold\",\n",
    "        # \"NoHand\",\n",
    "    ]\n",
    "data_dir = \"/Users/netanelblumenfeld/Desktop/data/11G/data_feat/\"\n",
    "data_dir1 = \"/Users/netanelblumenfeld/Desktop/data/11G/data_npy/\"\n",
    "output_dir = \"/Users/netanelblumenfeld/Desktop/bgu/Msc/project/outputs\"\n",
    "\n",
    "people = 4\n",
    "\n",
    "\n",
    "data_dir = \"/Users/netanelblumenfeld/Desktop/data/11G/\"\n",
    "paths = data_paths(data_dir, people, gestures,\"npy\")\n",
    "data = npy_feat_reshape(load_data(paths[0]))\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
