{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import namedtuple\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.fftpack import fft, fftshift\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "\n",
    "def ensure_path_exists(path):\n",
    "    \"\"\"\n",
    "    Checks if a given path exists, and if not, creates it.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path to be checked and potentially created.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "\n",
    "def get_time_in_string():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "\n",
    "class GestureDataset(Dataset):\n",
    "    def __init__(self, dataX, dataY):\n",
    "        _x_train = np.concatenate([np.array(d) for d in dataX])\n",
    "        self.x_train = np.transpose(_x_train, (0, 1, 4, 2, 3))\n",
    "        self.tempy = np.concatenate([np.array(dy) for dy in dataY])\n",
    "        self.label = np.empty((self.tempy.shape[0], self.tempy.shape[1]))\n",
    "        for idx in range(self.tempy.shape[0]):\n",
    "            for j in range(self.tempy.shape[1]):\n",
    "                for i in range(self.tempy.shape[2]):\n",
    "                    if self.tempy[idx][j][i] == 1:\n",
    "                        self.label[idx][j] = i\n",
    "        del self.tempy\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return self.x_train[idx], torch.LongTensor(self.label[idx])\n",
    "\n",
    "def loadPerson(paramList, scale: bool):\n",
    "    SubjectData = list()\n",
    "    SubjectLabel = list()\n",
    "    print(f\"Doing {paramList.personIdx}\")\n",
    "    for gestureIdx, gestureName in enumerate(paramList.listOfGestures):\n",
    "        # Create filename\n",
    "        filename = (\n",
    "            \"p\"\n",
    "            + str(paramList.personIdx)\n",
    "            + \"/\"\n",
    "            + gestureName\n",
    "            + \"_1s_wl\"\n",
    "            + str(paramList.lengthOfWindow)\n",
    "            + \"_\"\n",
    "            + \"doppl.npy\"\n",
    "        )\n",
    "\n",
    "        # Load data gesture data from disk\n",
    "        try:\n",
    "            GestureData = np.load(paramList.pathToFeatures + filename)\n",
    "            for i in range(GestureData.shape[0]):\n",
    "                for j in range(GestureData.shape[1]):\n",
    "                    for k in range(GestureData.shape[4]):\n",
    "                        GestureData[i, j, :, :, k] = (\n",
    "                            GestureData[i, j, :, :, k]\n",
    "                            / GestureData[i, j, :, :, k].max()\n",
    "                        )\n",
    "        except IOError:\n",
    "            print(\"Could not open file: \" + filename)\n",
    "            continue\n",
    "        else:\n",
    "            if 0 >= GestureData.shape[0]:\n",
    "                print(\"Skip datafile (no data): \" + filename)\n",
    "                continue\n",
    "\n",
    "            SubjectData.append(GestureData)\n",
    "\n",
    "            for idx in range(0, GestureData.shape[0]):\n",
    "                GestureLabel = list()\n",
    "                for jdx in range(0, GestureData.shape[1]):\n",
    "                    GestureLabel.append(\n",
    "                        np.identity(len(paramList.listOfGestures))[gestureIdx]\n",
    "                    )\n",
    "                SubjectLabel.append(np.asarray(GestureLabel))\n",
    "\n",
    "            # Check if there is some data for this person\n",
    "            if (0 >= len(SubjectData)) or (0 >= len(SubjectLabel)):\n",
    "                print(\"No entries found for person with index 'p\" + str(idx) + \"'\")\n",
    "                return\n",
    "\n",
    "    return np.concatenate(SubjectData, axis=0), np.asarray(SubjectLabel)\n",
    "\n",
    "\n",
    "def loadFeatures(\n",
    "    pathtoDataset,\n",
    "    listOfPeople,\n",
    "    listofGestures,\n",
    "    numberofInstanceCopies,\n",
    "    lengthOfWindow,\n",
    "    scale,\n",
    "):\n",
    "    ParamList = namedtuple(\n",
    "        \"ParamList\",\n",
    "        \"personIdx, pathToFeatures, listOfGestures, numberOfInstanceCopies, lengthOfWindow\",\n",
    "    )\n",
    "    personList = []\n",
    "    for i in listOfPeople:\n",
    "        personList.append(\n",
    "            ParamList(\n",
    "                i,\n",
    "                pathtoDataset,\n",
    "                listofGestures,\n",
    "                numberofInstanceCopies,\n",
    "                lengthOfWindow,\n",
    "            )\n",
    "        )\n",
    "    # with Pool(8) as p:\n",
    "    loadPerson_scale = partial(loadPerson, scale=scale)\n",
    "    featureList = list(map(loadPerson_scale, personList))\n",
    "    return featureList\n",
    "\n",
    "\n",
    "def setupLOOCV(dataX, dataY) -> tuple[Dataset, Dataset]:\n",
    "    # Split people into train and validation set\n",
    "    dataX_train = [*dataX[0:validationPerson], *dataX[validationPerson + 1 :]]\n",
    "    dataY_train = [*dataY[0:validationPerson], *dataY[validationPerson + 1 :]]\n",
    "\n",
    "    # Set the validation Person used for Leave-one-out cross-validation\n",
    "    validationPerson = 10\n",
    "    dataX_val = [dataX[validationPerson]]\n",
    "    dataY_val = [dataY[validationPerson]]\n",
    "\n",
    "    # Generate dataset from lists\n",
    "    traindataset = GestureDataset(dataX_train, dataY_train)\n",
    "    valdataset = GestureDataset(dataX_val, dataY_val)\n",
    "\n",
    "    return traindataset, valdataset\n",
    "\n",
    "\n",
    "def setupDataset(\n",
    "    dataX, dataY, test_size=0.2, random_state=42\n",
    ") -> tuple[Dataset, Dataset]:\n",
    "    \"\"\"\n",
    "    Split the dataset into training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataX: List of data samples.\n",
    "    - dataY: Corresponding list of labels.\n",
    "    - test_size: Fraction of the dataset to be used as validation data.\n",
    "    - random_state: Seed for the random number generator for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - traindataset: Training dataset.\n",
    "    - valdataset: Validation dataset.\n",
    "    \"\"\"\n",
    "    # Flatten the list of arrays\n",
    "    flat_dataX = np.concatenate(dataX)\n",
    "    flat_dataY = np.concatenate(dataY)\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "        flat_dataX, flat_dataY, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Generate datasets\n",
    "    traindataset = GestureDataset([X_train], [Y_train])\n",
    "    valdataset = GestureDataset([X_val], [Y_val])\n",
    "\n",
    "    return traindataset, valdataset\n",
    "\n",
    "\n",
    "def get_tiny_radar_data_loader(\n",
    "    pathToDataset: str,\n",
    "    listPeople: list[int],\n",
    "    listGestures: list[str],\n",
    "    batch_size: int = 128,\n",
    "    scale: bool = True,\n",
    ") -> tuple[DataLoader, DataLoader]:\n",
    "    # Dataset parameters\n",
    "    numberOfTimeSteps = 5\n",
    "    numberOfSensors = 2\n",
    "    numberOfRangePointsPerSensor = 492\n",
    "    numberOfInstanceWindows = 3\n",
    "    lengthOfSubWindow = 32\n",
    "    numberOfGestures = 12\n",
    "\n",
    "    featureList = loadFeatures(\n",
    "        pathToDataset,\n",
    "        listPeople,\n",
    "        listGestures,\n",
    "        numberOfInstanceWindows,\n",
    "        lengthOfSubWindow,\n",
    "        scale,\n",
    "    )\n",
    "    dataX = list(map(lambda x: x[0], featureList))\n",
    "    dataY = list(map(lambda x: x[1], featureList))\n",
    "\n",
    "    traindataset, valdataset = setupDataset(dataX, dataY)\n",
    "\n",
    "    training_generator = DataLoader(\n",
    "        traindataset, batch_size=batch_size, shuffle=True, num_workers=0\n",
    "    )\n",
    "    val_generator = DataLoader(\n",
    "        valdataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    "    )\n",
    "    return training_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing 1\n",
      "Doing 2\n",
      "Doing 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z3/cpwq18yn4mx0frkm5m4tq_xc0000gn/T/ipykernel_19780/1948666203.py:80: RuntimeWarning: invalid value encountered in divide\n",
      "  GestureData[i, j, :, :, k]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing 4\n",
      "Doing 5\n",
      "Doing 6\n",
      "Doing 7\n",
      "Doing 8\n",
      "Doing 9\n",
      "Doing 10\n",
      "Doing 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "listGestures = [\n",
    "    \"Circle\",\n",
    "    # \"FastSwipeRL\",\n",
    "    # \"FingerRub\",\n",
    "    # \"FingerSlider\",\n",
    "    # \"NoHand\",\n",
    "    # \"PalmHold\",\n",
    "    # \"PalmTilt\",\n",
    "    # \"PinchIndex\",\n",
    "    # \"PinchPinky\",\n",
    "    # \"Pull\",\n",
    "    # \"Push\",\n",
    "    \"SlowSwipeRL\",\n",
    "]\n",
    "listPeople = range(1, 12, 1)\n",
    "\n",
    "# Dataset parameters\n",
    "numberOfTimeSteps = 5\n",
    "numberOfSensors = 2\n",
    "numberOfRangePointsPerSensor = 492\n",
    "numberOfInstanceWindows = 3\n",
    "lengthOfSubWindow = 32\n",
    "numberOfGestures = 12\n",
    "\n",
    "\n",
    "pathToDataset = \"/Users/netanelblumenfeld/Desktop/data/11G/data_feat/\"\n",
    "\n",
    "training_generator, val_generator = get_tiny_radar_data_loader(\n",
    "    pathToDataset, listPeople, listGestures, 128, scale=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataX, dataY):\n",
    "        _x_train = np.concatenate([np.array(d) for d in dataX])\n",
    "        print(_x_train.shape)\n",
    "        self.x_train = np.transpose(_x_train, (0, 1, 4, 2, 3))\n",
    "\n",
    "        self.tempy = np.concatenate([np.array(dy) for dy in dataY])\n",
    "\n",
    "        self.label = np.empty((self.tempy.shape[0], self.tempy.shape[1]))\n",
    "        for idx in range(self.tempy.shape[0]):\n",
    "            for j in range(self.tempy.shape[1]):\n",
    "                for i in range(self.tempy.shape[2]):\n",
    "                    if self.tempy[idx][j][i] == 1:\n",
    "                        self.label[idx][j] = i\n",
    "        del self.tempy\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        return self.x_train[idx], torch.LongTensor(self.label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadPerson(paramList):\n",
    "    SubjectData = list()\n",
    "    SubjectLabel = list()\n",
    "    print(f\"Doing {paramList.personIdx}\")\n",
    "    for gestureIdx, gestureName in enumerate(paramList.listOfGestures):\n",
    "        # Create filename\n",
    "        filename = (\n",
    "            \"p\"\n",
    "            + str(paramList.personIdx)\n",
    "            + \"/\"\n",
    "            + gestureName\n",
    "            + \"_1s_wl\"\n",
    "            + str(paramList.lengthOfWindow)\n",
    "            + \"_\"\n",
    "            + \"doppl.npy\"\n",
    "        )\n",
    "\n",
    "        # Load data gesture data from disk\n",
    "        try:\n",
    "            GestureData = np.load(paramList.pathToFeatures + filename)\n",
    "        except IOError:\n",
    "            print(\"Could not open file: \" + filename)\n",
    "            continue\n",
    "        else:\n",
    "            if 0 >= GestureData.shape[0]:\n",
    "                print(\"Skip datafile (no data): \" + filename)\n",
    "                continue\n",
    "\n",
    "            SubjectData.append(GestureData)\n",
    "\n",
    "            for idx in range(0, GestureData.shape[0]):\n",
    "                GestureLabel = list()\n",
    "                for jdx in range(0, GestureData.shape[1]):\n",
    "                    GestureLabel.append(\n",
    "                        np.identity(len(paramList.listOfGestures))[gestureIdx]\n",
    "                    )\n",
    "                SubjectLabel.append(np.asarray(GestureLabel))\n",
    "\n",
    "    # Check if there is some data for this person\n",
    "    if (0 >= len(SubjectData)) or (0 >= len(SubjectLabel)):\n",
    "        print(\"No entries found for person with index 'p\" + str(pdx) + \"'\")\n",
    "        return\n",
    "\n",
    "    return np.concatenate(SubjectData, axis=0), np.asarray(SubjectLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadFeatures(\n",
    "    pathtoDataset, listOfPeople, listofGestures, numberofInstanceCopies, lengthOfWindow\n",
    "):\n",
    "    personList = []\n",
    "    pathToFeatures = pathToDataset + \"data_feat/\"\n",
    "    for i in listOfPeople:\n",
    "        personList.append(\n",
    "            ParamList(\n",
    "                i,\n",
    "                pathToFeatures,\n",
    "                listofGestures,\n",
    "                numberofInstanceCopies,\n",
    "                lengthOfWindow,\n",
    "            )\n",
    "        )\n",
    "    # with Pool(8) as p:\n",
    "    featureList = list(map(loadPerson, personList))\n",
    "    return featureList\n",
    "\n",
    "\n",
    "def setupLOOCV(dataX, dataY, personIdx):\n",
    "    # Split people into train and validation set\n",
    "    dataX_train = [*dataX[0:validationPerson], *dataX[validationPerson + 1 :]]\n",
    "    dataY_train = [*dataY[0:validationPerson], *dataY[validationPerson + 1 :]]\n",
    "\n",
    "    dataX_val = [dataX[validationPerson]]\n",
    "    dataY_val = [dataY[validationPerson]]\n",
    "\n",
    "    # Generate dataset from lists\n",
    "    traindataset = GestureDataset(dataX_train, dataY_train)\n",
    "    valdataset = GestureDataset(dataX_val, dataY_val)\n",
    "\n",
    "    return traindataset, valdataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing 1\n",
      "Doing 2\n",
      "Doing 3\n",
      "Doing 4\n",
      "Doing 5\n",
      "Doing 6\n",
      "Doing 7\n",
      "Doing 8\n",
      "Doing 9\n",
      "Doing 10\n",
      "Doing 11\n",
      "Doing 12\n",
      "Doing 13\n",
      "Doing 14\n",
      "Doing 15\n",
      "Doing 16\n",
      "Doing 17\n",
      "Doing 18\n",
      "Doing 19\n",
      "Doing 20\n",
      "Doing 21\n",
      "Doing 22\n",
      "Doing 23\n",
      "Doing 24\n",
      "Doing 25\n",
      "(5031, 5, 32, 492, 2)\n",
      "(210, 5, 32, 492, 2)\n"
     ]
    }
   ],
   "source": [
    "featureList = loadFeatures(\n",
    "    pathToDataset,\n",
    "    listPeople,\n",
    "    listGestures,\n",
    "    numberOfInstanceWindows,\n",
    "    lengthOfSubWindow,\n",
    ")\n",
    "\n",
    "\n",
    "dataX = list(map(lambda x: x[0], featureList))\n",
    "dataY = list(map(lambda x: x[1], featureList))\n",
    "traindataset, valdataset = setupLOOCV(dataX, dataY, validationPerson)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1D(torch.nn.Conv1d):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=True,\n",
    "    ):\n",
    "        self.__padding = (kernel_size - 1) * dilation\n",
    "\n",
    "        super(CausalConv1D, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=self.__padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        result = super(CausalConv1D, self).forward(input)\n",
    "        if self.__padding != 0:\n",
    "            return result[:, :, : -self.__padding]\n",
    "        return result\n",
    "\n",
    "\n",
    "class cust_TCNLayer(CausalConv1D):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=True,\n",
    "    ):\n",
    "        super(cust_TCNLayer, self).__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        result = super(cust_TCNLayer, self).forward(input)\n",
    "        result = torch.nn.functional.relu(result)\n",
    "        return result + input\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        numberOfSensors,\n",
    "        numberOfRangePointsPerSensor,\n",
    "        lengthOfWindow,\n",
    "        numberOfTimeSteps,\n",
    "        numberOfGestures,\n",
    "    ):\n",
    "        # Parameters that need to be consistent with the dataset\n",
    "        super(Model, self).__init__()\n",
    "        self.lWindow = lengthOfWindow\n",
    "        self.nRangePoints = numberOfRangePointsPerSensor\n",
    "        self.nSensors = numberOfSensors\n",
    "        self.nTimeSteps = numberOfTimeSteps\n",
    "        self.nGestures = numberOfGestures\n",
    "\n",
    "        self.CNN = torch.nn.Sequential(*self.CreateCNN())\n",
    "        self.TCN = torch.nn.Sequential(*self.CreateTCN())\n",
    "        self.Classifier = torch.nn.Sequential(*self.CreateClassifier())\n",
    "\n",
    "    def CreateCNN(self):\n",
    "        cnnlayers = []\n",
    "        cnnlayers += [\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=self.nSensors,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3, 5),\n",
    "                padding=(1, 2),\n",
    "            )\n",
    "        ]\n",
    "        cnnlayers += [torch.nn.ReLU()]\n",
    "        cnnlayers += [\n",
    "            torch.nn.MaxPool2d(kernel_size=(3, 5), stride=(3, 5), padding=(0, 0))\n",
    "        ]\n",
    "        cnnlayers += [\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=16, out_channels=32, kernel_size=(3, 5), padding=(1, 2)\n",
    "            )\n",
    "        ]\n",
    "        cnnlayers += [torch.nn.ReLU()]\n",
    "        cnnlayers += [\n",
    "            torch.nn.MaxPool2d(kernel_size=(3, 5), stride=(3, 5), padding=(0, 0))\n",
    "        ]\n",
    "        cnnlayers += [\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=32, out_channels=64, kernel_size=(1, 7), padding=(0, 3)\n",
    "            )\n",
    "        ]\n",
    "        cnnlayers += [torch.nn.ReLU()]\n",
    "        cnnlayers += [\n",
    "            torch.nn.MaxPool2d(kernel_size=(1, 7), stride=(1, 7), padding=(0, 0))\n",
    "        ]\n",
    "        cnnlayers += [torch.nn.Flatten(start_dim=1, end_dim=-1)]\n",
    "        return cnnlayers\n",
    "\n",
    "    def CreateTCN(self):\n",
    "        tcnlayers = []\n",
    "        tcnlayers += [CausalConv1D(in_channels=384, out_channels=32, kernel_size=1)]\n",
    "        tcnlayers += [\n",
    "            cust_TCNLayer(in_channels=32, out_channels=32, kernel_size=2, dilation=1)\n",
    "        ]\n",
    "        tcnlayers += [\n",
    "            cust_TCNLayer(in_channels=32, out_channels=32, kernel_size=2, dilation=2)\n",
    "        ]\n",
    "        tcnlayers += [\n",
    "            cust_TCNLayer(in_channels=32, out_channels=32, kernel_size=2, dilation=4)\n",
    "        ]\n",
    "        return tcnlayers\n",
    "\n",
    "    def CreateClassifier(self):\n",
    "        classifier = []\n",
    "        classifier += [torch.nn.Flatten(start_dim=1, end_dim=-1)]\n",
    "        classifier += [torch.nn.Linear(32, 64)]\n",
    "        classifier += [torch.nn.ReLU()]\n",
    "        classifier += [torch.nn.Linear(64, 32)]\n",
    "        classifier += [torch.nn.ReLU()]\n",
    "        classifier += [torch.nn.Linear(32, self.nGestures)]\n",
    "        return classifier\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnnoutputs = []\n",
    "        for i in range(self.nTimeSteps):\n",
    "            cnnoutputs += [self.CNN(x[i])]\n",
    "        tcninput = torch.stack(cnnoutputs, dim=2)\n",
    "        tcnoutput = self.TCN(tcninput)\n",
    "        classifierinput = tcnoutput.permute(0, 2, 1)\n",
    "        outputs = []\n",
    "        for i in range(self.nTimeSteps):\n",
    "            outputs += [self.Classifier(classifierinput[:, i])]\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        return outputs.permute(1, 0, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(outputs, labels, criterion):\n",
    "    loss = 0\n",
    "    for i in range(numberOfTimeSteps):\n",
    "        loss += criterion(outputs[i], labels[i])\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_acc(outputs, labels):\n",
    "    # print(outputs.shape)\n",
    "    pred = outputs.reshape(-1, numberOfGestures).max(1)\n",
    "    squashed_labels = labels.reshape(-1)\n",
    "    total = squashed_labels.shape[0]\n",
    "    correct = pred[1].eq(squashed_labels).sum().item()\n",
    "    return total, correct\n",
    "\n",
    "\n",
    "def train(model, training_generator, epoch):\n",
    "    # Training\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for batch, labels in training_generator:\n",
    "\n",
    "        # Transfer to GPU\n",
    "        batch, labels = batch.permute(1, 0, 2, 3, 4).to(device), labels.permute(\n",
    "            1, 0\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = compute_loss(outputs, labels, criterion)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        curr_total, curr_correct = compute_acc(outputs, labels)\n",
    "        total += curr_total\n",
    "        correct += curr_correct\n",
    "\n",
    "    acc = 100.0 * (correct) / total\n",
    "    error_rate = 100.0 * (total - correct) / total\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    tboard.add_scalar(\"loss/train\", train_loss, epoch)\n",
    "    tboard.add_scalar(\"error/train\", error_rate, epoch)\n",
    "    tboard.add_scalar(\"lr\", lr, epoch)\n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    print(\"Train -- Loss: %.3f | Acc: %.3f%% | LR: %e\" % (train_loss, acc, lr))\n",
    "    # print(epoch_loss)\n",
    "\n",
    "\n",
    "def validate(model, val_generator, epoch):\n",
    "    global max_val_acc\n",
    "\n",
    "    val_loss, val_corr, val_tot = 0, 0, 0\n",
    "    for batch, labels in val_generator:\n",
    "        # Transfer to GPU\n",
    "        batch, labels = batch.permute(1, 0, 2, 3, 4).to(device), labels.permute(\n",
    "            1, 0\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = model(batch)\n",
    "\n",
    "        loss = compute_loss(outputs, labels, criterion)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        curr_total, curr_correct = compute_acc(outputs, labels)\n",
    "        val_tot += curr_total\n",
    "        val_corr += curr_correct\n",
    "\n",
    "    val_acc = 100.0 * (val_corr) / val_tot\n",
    "    print(\"Val -- Loss: %.3f | Acc: %.3f%%\" % (val_loss, val_acc))\n",
    "    # print(epoch_loss)\n",
    "\n",
    "    if val_acc > max_val_acc:\n",
    "        torch.save(model.state_dict(), f\"./model_{validationPerson}_max.pt\")\n",
    "        max_val_acc = val_acc\n",
    "        print(\"new max\")\n",
    "\n",
    "        loss, correct, total = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train -- Loss: 210.974 | Acc: 57.710% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [01:14<2:03:23, 74.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 3.502 | Acc: 95.619%\n",
      "new max\n",
      "Epoch: 1\n",
      "Train -- Loss: 88.404 | Acc: 78.557% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [02:17<1:50:46, 67.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 2.339 | Acc: 86.667%\n",
      "Epoch: 2\n",
      "Train -- Loss: 79.766 | Acc: 81.972% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [03:20<1:45:36, 65.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 2.008 | Acc: 90.571%\n",
      "Epoch: 3\n",
      "Train -- Loss: 64.015 | Acc: 86.241% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [04:22<1:42:49, 64.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 1.500 | Acc: 97.238%\n",
      "new max\n",
      "Epoch: 4\n",
      "Train -- Loss: 54.265 | Acc: 88.885% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [05:25<1:41:07, 63.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 1.341 | Acc: 97.619%\n",
      "new max\n",
      "Epoch: 5\n",
      "Train -- Loss: 47.389 | Acc: 90.563% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [06:29<1:40:09, 63.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 1.301 | Acc: 98.667%\n",
      "new max\n",
      "Epoch: 6\n",
      "Train -- Loss: 43.488 | Acc: 91.354% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [07:37<1:40:54, 65.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 1.187 | Acc: 97.524%\n",
      "Epoch: 7\n",
      "Train -- Loss: 37.041 | Acc: 92.920% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [08:45<1:41:23, 66.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 2.244 | Acc: 91.238%\n",
      "Epoch: 8\n",
      "Train -- Loss: 34.421 | Acc: 93.449% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [09:55<1:42:12, 67.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 1.074 | Acc: 97.429%\n",
      "Epoch: 9\n",
      "Train -- Loss: 36.236 | Acc: 93.174% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [11:03<1:41:15, 67.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 1.044 | Acc: 97.905%\n",
      "Epoch: 10\n",
      "Train -- Loss: 28.511 | Acc: 94.729% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [12:15<1:41:58, 68.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.664 | Acc: 99.429%\n",
      "new max\n",
      "Epoch: 11\n",
      "Train -- Loss: 27.593 | Acc: 94.772% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [13:25<1:41:31, 69.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 1.469 | Acc: 94.952%\n",
      "Epoch: 12\n",
      "Train -- Loss: 26.891 | Acc: 95.130% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [14:29<1:37:51, 67.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.883 | Acc: 97.905%\n",
      "Epoch: 13\n",
      "Train -- Loss: 23.619 | Acc: 95.595% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [15:30<1:34:11, 65.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.360 | Acc: 99.810%\n",
      "new max\n",
      "Epoch: 14\n",
      "Train -- Loss: 22.196 | Acc: 95.957% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [16:32<1:31:24, 64.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.644 | Acc: 98.857%\n",
      "Epoch: 15\n",
      "Train -- Loss: 25.934 | Acc: 95.329% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [17:34<1:29:05, 63.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.831 | Acc: 99.143%\n",
      "Epoch: 16\n",
      "Train -- Loss: 21.239 | Acc: 96.148% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [18:35<1:27:07, 62.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.384 | Acc: 99.429%\n",
      "Epoch: 17\n",
      "Train -- Loss: 20.037 | Acc: 96.311% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [19:37<1:25:46, 62.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.467 | Acc: 99.333%\n",
      "Epoch: 18\n",
      "Train -- Loss: 20.146 | Acc: 96.398% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [20:39<1:24:18, 62.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.829 | Acc: 98.000%\n",
      "Epoch: 19\n",
      "Train -- Loss: 19.186 | Acc: 96.454% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [21:41<1:22:59, 62.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.344 | Acc: 99.619%\n",
      "Epoch: 20\n",
      "Train -- Loss: 19.135 | Acc: 96.486% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [22:42<1:21:44, 62.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.557 | Acc: 99.143%\n",
      "Epoch: 21\n",
      "Train -- Loss: 17.773 | Acc: 96.796% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [23:44<1:20:41, 62.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.491 | Acc: 99.333%\n",
      "Epoch: 22\n",
      "Train -- Loss: 17.334 | Acc: 96.780% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [24:46<1:19:32, 61.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.618 | Acc: 98.476%\n",
      "Epoch: 23\n",
      "Train -- Loss: 17.750 | Acc: 96.840% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [25:48<1:18:29, 61.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 1.436 | Acc: 95.619%\n",
      "Epoch: 24\n",
      "Train -- Loss: 21.390 | Acc: 96.041% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [26:50<1:17:27, 61.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.444 | Acc: 99.333%\n",
      "Epoch: 25\n",
      "Train -- Loss: 19.205 | Acc: 96.434% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [27:52<1:16:21, 61.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.856 | Acc: 98.381%\n",
      "Epoch: 26\n",
      "Train -- Loss: 16.545 | Acc: 96.967% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [28:54<1:15:24, 61.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.308 | Acc: 99.714%\n",
      "Epoch: 27\n",
      "Train -- Loss: 15.729 | Acc: 97.166% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [29:56<1:14:16, 61.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.435 | Acc: 99.143%\n",
      "Epoch: 28\n",
      "Train -- Loss: 15.539 | Acc: 97.054% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [30:58<1:13:19, 61.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.360 | Acc: 99.524%\n",
      "Epoch: 29\n",
      "Train -- Loss: 16.045 | Acc: 97.062% | LR: 1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [32:00<1:12:23, 62.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val -- Loss: 0.440 | Acc: 99.238%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [32:50<1:16:38, 65.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(max_epochs)):\n\u001b[1;32m     30\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     33\u001b[0m     validate(model, val_generator, i)\n",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, training_generator, epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[1;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m compute_loss(outputs, labels, criterion)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     33\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/radar/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/radar/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "max_epochs = 100\n",
    "use_mps =False\n",
    "# use_mps =torch.backends.mps.is_available()\n",
    "device = torch.device(\"mps\" if use_mps else \"cpu\")\n",
    "model = Model(\n",
    "    numberOfSensors,\n",
    "    numberOfRangePointsPerSensor,\n",
    "    lengthOfSubWindow,\n",
    "    numberOfTimeSteps,\n",
    "    numberOfGestures,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, amsgrad=True)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "tboard = SummaryWriter(log_dir=\"./logs\", max_queue=2)\n",
    "tboard.add_graph(model, torch.rand(5, 32, 2, 32, 492).to(device))\n",
    "\n",
    "training_generator = torch.utils.data.DataLoader(\n",
    "    traindataset, batch_size=batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "val_generator = torch.utils.data.DataLoader(\n",
    "    valdataset, batch_size=batch_size, shuffle=False, num_workers=0\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for i in tqdm(range(max_epochs)):\n",
    "    model.train()\n",
    "    train(model, training_generator, i)\n",
    "    model.eval()\n",
    "    validate(model, val_generator, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
